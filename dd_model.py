import pickle

import tensorflow as tf

import reader
from common import Common


class Model:
    topk = 10
    num_batches_to_log = 100

    def __init__(self, config):
        self.config = config

        self.eval_queue = None
        self.predict_queue = None

        self.eval_placeholder = None
        self.predict_placeholder = None
        (
            self.eval_predicted_indices_op,
            self.eval_top_values_op,
            self.eval_true_target_strings_op,
            self.eval_topk_values,
            self.eval_attentions_op,
            self.eval_losses_op,
        ) = (None, None, None, None, None, None)
        (
            self.predict_top_indices_op,
            self.predict_top_scores_op,
            self.predict_target_strings_op,
        ) = (None, None, None)
        self.subtoken_to_index = None

        if config.LOAD_PATH:
            self.load_model(sess=None)
        else:
            with open(
                "models\dd-code2seq\models\java-large-model\model_iter52.release.dict",
                "rb",
            ) as file:
                subtoken_to_count = pickle.load(file)
                node_to_count = pickle.load(file)
                target_to_count = pickle.load(file)
                max_contexts = pickle.load(file)
                self.num_training_examples = pickle.load(file)
                print("Dictionaries loaded.")

            if self.config.DATA_NUM_CONTEXTS <= 0:
                self.config.DATA_NUM_CONTEXTS = max_contexts
            (
                self.subtoken_to_index,
                self.index_to_subtoken,
                self.subtoken_vocab_size,
            ) = Common.load_vocab_from_dict(
                subtoken_to_count,
                add_values=[Common.PAD, Common.UNK],
                max_size=config.SUBTOKENS_VOCAB_MAX_SIZE,
            )
            print("Loaded subtoken vocab. size: %d" % self.subtoken_vocab_size)

            (
                self.target_to_index,
                self.index_to_target,
                self.target_vocab_size,
            ) = Common.load_vocab_from_dict(
                target_to_count,
                add_values=[Common.PAD, Common.UNK, Common.SOS],
                max_size=config.TARGET_VOCAB_MAX_SIZE,
            )
            print("Loaded target word vocab. size: %d" % self.target_vocab_size)

            (
                self.node_to_index,
                self.index_to_node,
                self.nodes_vocab_size,
            ) = Common.load_vocab_from_dict(
                node_to_count, add_values=[Common.PAD, Common.UNK], max_size=None
            )
            print("Loaded nodes vocab. size: %d" % self.nodes_vocab_size)
            self.epochs_trained = 0

        # move from evaluate to here
        if self.eval_queue is None:
            self.eval_queue = reader.Reader(
                subtoken_to_index=self.subtoken_to_index,
                node_to_index=self.node_to_index,
                target_to_index=self.target_to_index,
                config=self.config,
                is_evaluating=True,
            )
            reader_output = self.eval_queue.get_output()
            (
                self.eval_predicted_indices_op,
                self.eval_topk_values,
                _,
                self.eval_attentions_op,
                self.eval_losses_op,
            ) = self.build_test_graph(reader_output)
            self.eval_true_target_strings_op = reader_output[reader.TARGET_STRING_KEY]
            self.saver = tf.train.Saver(max_to_keep=10)

        if self.config.LOAD_PATH and not self.config.TRAIN_PATH:
            self.initialize_session_variables(self.sess)
            self.load_model(self.sess)

    def close_session(self):
        self.sess.close()

    def evaluate(self):
        self.eval_queue.reset(self.sess)

        try:
            while True:
                (
                    predicted_indices,
                    true_target_strings,
                    top_values,
                    losses,
                ) = self.sess.run(
                    [
                        self.eval_predicted_indices_op,
                        self.eval_true_target_strings_op,
                        self.eval_topk_values,
                        self.eval_losses_op,
                    ],
                )
                true_target_strings = Common.binary_to_string_list(true_target_strings)
                if self.config.BEAM_WIDTH > 0:
                    # predicted indices: (batch, time, beam_width)
                    predicted_strings = [
                        [
                            [self.index_to_target[i] for i in timestep]
                            for timestep in example
                        ]
                        for example in predicted_indices
                    ]
                    predicted_strings = [
                        list(map(list, zip(*example))) for example in predicted_strings
                    ]  # (batch, top-k, target_length)
                else:
                    predicted_strings = [
                        [self.index_to_target[i] for i in example]
                        for example in predicted_indices
                    ]
                return self.update_correct_predictions(
                    zip(true_target_strings, predicted_strings, top_values, [losses])
                )
        except tf.errors.OutOfRangeError:
            pass

    def get_attention(self):
        self.eval_queue.reset(self.sess)
        try:
            while True:
                attentions, losses = self.sess.run(
                    [self.eval_attentions_op, self.eval_losses_op],
                )
                return attentions
        except tf.errors.OutOfRangeError:
            pass

    def update_correct_predictions(self, results):
        try:
            for original_name, predicted, top_values, losses in results:
                original_name_parts = original_name.split(
                    Common.internal_delimiter
                )  # list
                predicted_first = predicted
                loss_first = losses
                value_first = top_values
                if self.config.BEAM_WIDTH > 0:
                    predicted_first = predicted[0]
                    loss_first = losses[0]
                    value_first = top_values[0]
                filtered_predicted_first_parts = Common.filter_impossible_names(
                    predicted_first
                )  # list
                predicted_first_join = Common.internal_delimiter.join(
                    filtered_predicted_first_parts
                )
                value_first_parts = [
                    val[0] for val in value_first[: len(filtered_predicted_first_parts)]
                ]
                rtn_results = [predicted_first_join, value_first_parts, loss_first]
                return rtn_results  # list
        except:
            return ""

    def decode_outputs(
        self,
        target_words_vocab,
        target_input,
        batch_size,
        batched_contexts,
        valid_mask,
        is_evaluating=False,
    ):
        num_contexts_per_example = tf.count_nonzero(valid_mask, axis=-1)

        start_fill = tf.fill(
            [batch_size], self.target_to_index[Common.SOS]
        )  # (batch, )
        decoder_cell = tf.nn.rnn_cell.MultiRNNCell(
            [
                tf.nn.rnn_cell.LSTMCell(self.config.DECODER_SIZE)
                for _ in range(self.config.NUM_DECODER_LAYERS)
            ]
        )
        contexts_sum = tf.reduce_sum(
            batched_contexts * tf.expand_dims(valid_mask, -1), axis=1
        )  # (batch_size, dim * 2 + rnn_size)
        contexts_average = tf.divide(
            contexts_sum, tf.to_float(tf.expand_dims(num_contexts_per_example, -1))
        )
        fake_encoder_state = tuple(
            tf.nn.rnn_cell.LSTMStateTuple(contexts_average, contexts_average)
            for _ in range(self.config.NUM_DECODER_LAYERS)
        )
        projection_layer = tf.layers.Dense(self.target_vocab_size, use_bias=False)
        if is_evaluating and self.config.BEAM_WIDTH > 0:
            batched_contexts = tf.contrib.seq2seq.tile_batch(
                batched_contexts, multiplier=self.config.BEAM_WIDTH
            )
            num_contexts_per_example = tf.contrib.seq2seq.tile_batch(
                num_contexts_per_example, multiplier=self.config.BEAM_WIDTH
            )
        attention_mechanism = tf.contrib.seq2seq.LuongAttention(
            num_units=self.config.DECODER_SIZE, memory=batched_contexts
        )
        # TF doesn't support beam search with alignment history
        should_save_alignment_history = is_evaluating and self.config.BEAM_WIDTH == 0
        decoder_cell = tf.contrib.seq2seq.AttentionWrapper(
            decoder_cell,
            attention_mechanism,
            attention_layer_size=self.config.DECODER_SIZE,
            alignment_history=should_save_alignment_history,
        )
        if is_evaluating:
            if self.config.BEAM_WIDTH > 0:
                decoder_initial_state = decoder_cell.zero_state(
                    dtype=tf.float32, batch_size=batch_size * self.config.BEAM_WIDTH
                )
                decoder_initial_state = decoder_initial_state.clone(
                    cell_state=tf.contrib.seq2seq.tile_batch(
                        fake_encoder_state, multiplier=self.config.BEAM_WIDTH
                    )
                )
                decoder = tf.contrib.seq2seq.BeamSearchDecoder(
                    cell=decoder_cell,
                    embedding=target_words_vocab,
                    start_tokens=start_fill,
                    end_token=self.target_to_index[Common.PAD],
                    initial_state=decoder_initial_state,
                    beam_width=self.config.BEAM_WIDTH,
                    output_layer=projection_layer,
                    length_penalty_weight=0.0,
                )
            else:
                helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(
                    target_words_vocab, start_fill, 0
                )
                initial_state = decoder_cell.zero_state(batch_size, tf.float32).clone(
                    cell_state=fake_encoder_state
                )
                decoder = tf.contrib.seq2seq.BasicDecoder(
                    cell=decoder_cell,
                    helper=helper,
                    initial_state=initial_state,
                    output_layer=projection_layer,
                )

        else:
            decoder_cell = tf.nn.rnn_cell.DropoutWrapper(
                decoder_cell, output_keep_prob=self.config.RNN_DROPOUT_KEEP_PROB
            )
            target_words_embedding = tf.nn.embedding_lookup(
                target_words_vocab,
                tf.concat([tf.expand_dims(start_fill, -1), target_input], axis=-1),
            )  # (batch, max_target_parts, dim * 2 + rnn_size)
            helper = tf.contrib.seq2seq.TrainingHelper(
                inputs=target_words_embedding,
                sequence_length=tf.ones([batch_size], dtype=tf.int32)
                * (self.config.MAX_TARGET_PARTS + 1),
            )

            initial_state = decoder_cell.zero_state(batch_size, tf.float32).clone(
                cell_state=fake_encoder_state
            )

            decoder = tf.contrib.seq2seq.BasicDecoder(
                cell=decoder_cell,
                helper=helper,
                initial_state=initial_state,
                output_layer=projection_layer,
            )
        (
            outputs,
            final_states,
            final_sequence_lengths,
        ) = tf.contrib.seq2seq.dynamic_decode(
            decoder, maximum_iterations=self.config.MAX_TARGET_PARTS + 1
        )
        return outputs, final_states

    def calculate_path_abstraction(
        self, path_embed, path_lengths, valid_contexts_mask, is_evaluating=False
    ):
        return self.path_rnn_last_state(
            is_evaluating, path_embed, path_lengths, valid_contexts_mask
        )

    def path_rnn_last_state(
        self, is_evaluating, path_embed, path_lengths, valid_contexts_mask
    ):
        # path_embed:           (batch, max_contexts, max_path_length+1, dim)
        # path_length:          (batch, max_contexts)
        # valid_contexts_mask:  (batch, max_contexts)
        max_contexts = tf.shape(path_embed)[1]
        flat_paths = tf.reshape(
            path_embed,
            shape=[-1, self.config.MAX_PATH_LENGTH, self.config.EMBEDDINGS_SIZE],
        )  # (batch * max_contexts, max_path_length+1, dim)
        flat_valid_contexts_mask = tf.reshape(
            valid_contexts_mask, [-1]
        )  # (batch * max_contexts)
        lengths = tf.multiply(
            tf.reshape(path_lengths, [-1]), tf.cast(flat_valid_contexts_mask, tf.int32)
        )  # (batch * max_contexts)
        if self.config.BIRNN:
            rnn_cell_fw = tf.nn.rnn_cell.LSTMCell(self.config.RNN_SIZE / 2)
            rnn_cell_bw = tf.nn.rnn_cell.LSTMCell(self.config.RNN_SIZE / 2)
            if not is_evaluating:
                rnn_cell_fw = tf.nn.rnn_cell.DropoutWrapper(
                    rnn_cell_fw, output_keep_prob=self.config.RNN_DROPOUT_KEEP_PROB
                )
                rnn_cell_bw = tf.nn.rnn_cell.DropoutWrapper(
                    rnn_cell_bw, output_keep_prob=self.config.RNN_DROPOUT_KEEP_PROB
                )
            _, (state_fw, state_bw) = tf.nn.bidirectional_dynamic_rnn(
                cell_fw=rnn_cell_fw,
                cell_bw=rnn_cell_bw,
                inputs=flat_paths,
                dtype=tf.float32,
                sequence_length=lengths,
            )
            final_rnn_state = tf.concat(
                [state_fw.h, state_bw.h], axis=-1
            )  # (batch * max_contexts, rnn_size)
        else:
            rnn_cell = tf.nn.rnn_cell.LSTMCell(self.config.RNN_SIZE)
            if not is_evaluating:
                rnn_cell = tf.nn.rnn_cell.DropoutWrapper(
                    rnn_cell, output_keep_prob=self.config.RNN_DROPOUT_KEEP_PROB
                )
            _, state = tf.nn.dynamic_rnn(
                cell=rnn_cell,
                inputs=flat_paths,
                dtype=tf.float32,
                sequence_length=lengths,
            )
            final_rnn_state = state.h  # (batch * max_contexts, rnn_size)

        return tf.reshape(
            final_rnn_state, shape=[-1, max_contexts, self.config.RNN_SIZE]
        )  # (batch, max_contexts, rnn_size)

    def compute_contexts(
        self,
        subtoken_vocab,
        nodes_vocab,
        source_input,
        nodes_input,
        target_input,
        valid_mask,
        path_source_lengths,
        path_lengths,
        path_target_lengths,
        is_evaluating=False,
    ):
        source_word_embed = tf.nn.embedding_lookup(
            params=subtoken_vocab, ids=source_input
        )  # (batch, max_contexts, max_name_parts, dim)
        path_embed = tf.nn.embedding_lookup(
            params=nodes_vocab, ids=nodes_input
        )  # (batch, max_contexts, max_path_length+1, dim)
        target_word_embed = tf.nn.embedding_lookup(
            params=subtoken_vocab, ids=target_input
        )  # (batch, max_contexts, max_name_parts, dim)

        source_word_mask = tf.expand_dims(
            tf.sequence_mask(
                path_source_lengths, maxlen=self.config.MAX_NAME_PARTS, dtype=tf.float32
            ),
            -1,
        )  # (batch, max_contexts, max_name_parts, 1)
        target_word_mask = tf.expand_dims(
            tf.sequence_mask(
                path_target_lengths, maxlen=self.config.MAX_NAME_PARTS, dtype=tf.float32
            ),
            -1,
        )  # (batch, max_contexts, max_name_parts, 1)

        source_words_sum = tf.reduce_sum(
            source_word_embed * source_word_mask, axis=2
        )  # (batch, max_contexts, dim)
        path_nodes_aggregation = self.calculate_path_abstraction(
            path_embed, path_lengths, valid_mask, is_evaluating
        )  # (batch, max_contexts, rnn_size)
        target_words_sum = tf.reduce_sum(
            target_word_embed * target_word_mask, axis=2
        )  # (batch, max_contexts, dim)

        context_embed = tf.concat(
            [source_words_sum, path_nodes_aggregation, target_words_sum], axis=-1
        )  # (batch, max_contexts, dim * 2 + rnn_size)
        if not is_evaluating:
            context_embed = tf.nn.dropout(
                context_embed, self.config.EMBEDDINGS_DROPOUT_KEEP_PROB
            )

        batched_embed = tf.layers.dense(
            inputs=context_embed,
            units=self.config.DECODER_SIZE,
            activation=tf.nn.tanh,
            trainable=not is_evaluating,
            use_bias=False,
        )

        return batched_embed

    def build_test_graph(self, input_tensors):
        target_index = input_tensors[reader.TARGET_INDEX_KEY]
        target_lengths = input_tensors[reader.TARGET_LENGTH_KEY]
        path_source_indices = input_tensors[reader.PATH_SOURCE_INDICES_KEY]
        node_indices = input_tensors[reader.NODE_INDICES_KEY]
        path_target_indices = input_tensors[reader.PATH_TARGET_INDICES_KEY]
        valid_mask = input_tensors[reader.VALID_CONTEXT_MASK_KEY]
        path_source_lengths = input_tensors[reader.PATH_SOURCE_LENGTHS_KEY]
        path_lengths = input_tensors[reader.PATH_LENGTHS_KEY]
        path_target_lengths = input_tensors[reader.PATH_TARGET_LENGTHS_KEY]

        with tf.variable_scope("model", reuse=self.get_should_reuse_variables()):
            subtoken_vocab = tf.get_variable(
                "SUBTOKENS_VOCAB",
                shape=(self.subtoken_vocab_size, self.config.EMBEDDINGS_SIZE),
                dtype=tf.float32,
                trainable=False,
            )
            target_words_vocab = tf.get_variable(
                "TARGET_WORDS_VOCAB",
                shape=(self.target_vocab_size, self.config.EMBEDDINGS_SIZE),
                dtype=tf.float32,
                trainable=False,
            )
            nodes_vocab = tf.get_variable(
                "NODES_VOCAB",
                shape=(self.nodes_vocab_size, self.config.EMBEDDINGS_SIZE),
                dtype=tf.float32,
                trainable=False,
            )

            batched_contexts = self.compute_contexts(
                subtoken_vocab=subtoken_vocab,
                nodes_vocab=nodes_vocab,
                source_input=path_source_indices,
                nodes_input=node_indices,
                target_input=path_target_indices,
                valid_mask=valid_mask,
                path_source_lengths=path_source_lengths,
                path_lengths=path_lengths,
                path_target_lengths=path_target_lengths,
                is_evaluating=True,
            )

            outputs, final_states = self.decode_outputs(
                target_words_vocab=target_words_vocab,
                target_input=target_index,
                batch_size=tf.shape(target_index)[0],
                batched_contexts=batched_contexts,
                valid_mask=valid_mask,
                is_evaluating=True,
            )

        if self.config.BEAM_WIDTH > 0:
            predicted_indices = outputs.predicted_ids
            topk_values = outputs.beam_search_decoder_output.scores
            attention_weights = [tf.no_op()]
        else:
            predicted_indices = outputs.sample_id
            topk_values = tf.constant(1, shape=(1, 1), dtype=tf.float32)
            attention_weights = tf.squeeze(final_states.alignment_history.stack(), 1)

        logits = outputs.rnn_output  # (batch, ?, dim * 2 + rnn_size)
        topk_candidates = tf.nn.top_k(
            logits, k=tf.minimum(self.topk, self.target_vocab_size)
        )
        topk_values = topk_candidates.values
        topk_values = tf.nn.softmax(topk_values)

        paddings = [
            [0, 0],
            [0, self.config.MAX_TARGET_PARTS + 1 - tf.shape(logits)[1]],
            [0, 0],
        ]
        logits_pad = tf.pad(
            logits, paddings, "CONSTANT", constant_values=0
        )  # (batch, max_output_length, dim * 2 + rnn_size)
        crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(
            labels=target_index, logits=logits_pad
        )
        target_words_nonzero = tf.sequence_mask(
            target_lengths + 1,
            maxlen=self.config.MAX_TARGET_PARTS + 1,
            dtype=tf.float32,
        )
        m_batch_size = tf.shape(target_index)[0]
        losses = tf.reduce_sum(crossent * target_words_nonzero) / tf.to_float(
            m_batch_size
        )

        return predicted_indices, topk_values, target_index, attention_weights, losses

    @staticmethod
    def get_attention_per_path(
        source_strings, path_strings, target_strings, attention_weights
    ):
        # attention_weights:  (time, contexts)
        results = []
        for time_step in attention_weights:
            attention_per_context = {}
            for source, path, target, weight in zip(
                source_strings, path_strings, target_strings, time_step
            ):
                string_triplet = (
                    Common.binary_to_string(source),
                    Common.binary_to_string(path),
                    Common.binary_to_string(target),
                )
                attention_per_context[string_triplet] = weight
            results.append(attention_per_context)
        return results

    def load_model(self, sess):
        if not sess is None:
            self.saver.restore(sess, self.config.LOAD_PATH)
            print("Done loading model")
        with open(self.config.LOAD_PATH + ".dict", "rb") as file:
            if self.subtoken_to_index is not None:
                return
            print("Loading dictionaries from: " + self.config.LOAD_PATH)
            self.subtoken_to_index = pickle.load(file)
            self.index_to_subtoken = pickle.load(file)
            self.subtoken_vocab_size = pickle.load(file)

            self.target_to_index = pickle.load(file)
            self.index_to_target = pickle.load(file)
            self.target_vocab_size = pickle.load(file)

            self.node_to_index = pickle.load(file)
            self.index_to_node = pickle.load(file)
            self.nodes_vocab_size = pickle.load(file)

            self.num_training_examples = pickle.load(file)
            self.epochs_trained = pickle.load(file)
            saved_config = pickle.load(file)
            self.config.take_model_hyperparams_from(saved_config)
            print("Done loading dictionaries")

    @staticmethod
    def initialize_session_variables(sess):
        sess.run(
            tf.group(
                tf.global_variables_initializer(),
                tf.local_variables_initializer(),
                tf.tables_initializer(),
            )
        )

    def get_should_reuse_variables(self):
        if self.config.TRAIN_PATH:
            return True
        else:
            return None
